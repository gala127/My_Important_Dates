{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFaK/WnKOW6eA7mofY5PN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gala127/My_Important_Dates/blob/master/SoundWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3thvdVUgfhP"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "\n",
        "audio_file = 'path_to_audio_file.wav'\n",
        "y, sr = librosa.load(audio_file)\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('path_to_pretrained_model.h5')"
      ],
      "metadata": {
        "id": "ZGVgTKaEghpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "\n",
        "def audio_callback(indata, frames, time, status):\n",
        "    if status:\n",
        "        print(status)\n",
        "    mfccs = librosa.feature.mfcc(y=indata[:, 0], sr=sr, n_mfcc=13)\n",
        "    mfccs = mfccs.reshape(1, -1)\n",
        "    prediction = model.predict(mfccs)\n",
        "    print(f'Predicted emotion: {prediction}')\n",
        "\n",
        "with sd.InputStream(callback=audio_callback):\n",
        "    sd.sleep(10000)  # Listen for 10 seconds\n"
      ],
      "metadata": {
        "id": "MbwRz77Fgq8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(n_mfcc, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(8, activation='softmax'))  # Assuming 8 emotion classes\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "npcmfeeQg1xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import librosa\n",
        "\n",
        "# Load your pre-trained model\n",
        "model = load_model('path_to_your_russian_emotion_model.h5')\n",
        "\n",
        "def extract_features(audio, sr):\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
        "    return np.mean(mfccs.T, axis=0)\n",
        "\n",
        "def audio_callback(indata, frames, time, status):\n",
        "    if status:\n",
        "        print(status)\n",
        "    # Reshape input data for model prediction\n",
        "    audio_data = np.mean(indata, axis=1)\n",
        "    features = extract_features(audio_data, sr)\n",
        "    features = np.expand_dims(features, axis=0)\n",
        "    prediction = model.predict(features)\n",
        "    emotion = np.argmax(prediction)\n",
        "    print(f'Predicted emotion: {emotion}')\n",
        "\n",
        "# Start streaming audio\n",
        "sr = 16000  # Sample rate\n",
        "with sd.InputStream(callback=audio_callback, channels=1, samplerate=sr):\n",
        "    sd.sleep(10000)  # Listen for 10 seconds\n"
      ],
      "metadata": {
        "id": "BX_9lp9FhK8X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}